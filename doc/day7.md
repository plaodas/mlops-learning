# Day 7: Deploying FastAPI with Kubernetes
ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€Kubernetes ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸Šã« FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚FastAPI ã¯ã€MLflow ã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ¨è«– API ã‚’æä¾›ã—ã¾ã™ã€‚

## å…¨ä½“åƒï¼šFastAPI æ¨è«–ã‚µãƒ¼ãƒ“ã‚¹ã®æ§‹æˆ
- MLflow ã§ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
- FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§æ¨è«–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’æä¾›
- Kubernetes ä¸Šã§å‹•ã‹ã—ã¦
http://fastapi.local

ã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

### Step 1ï¼šFastAPI ã‚¢ãƒ—ãƒªã‚’ä½œã‚‹
`app.py` ã‚’ä½œæˆã—ã€FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™

### Step 2ï¼šDockerfile ã‚’ä½œæˆ
Dockerfile ã‚’ä½œæˆã—ã€FastAPI ã‚¢ãƒ—ãƒªã‚’ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã—ã¾ã™ã€‚
```bash
docker build -t registry5001:5000/fastapi-iris:latest -f api/Dockerfile api
docker tag registry5001:5000/fastapi-iris:latest localhost:5001/fastapi-iris:latest
docker push localhost:5001/fastapi-iris:latest
```

### Step 3ï¼šKubernetes Deployment ã‚’ä½œæˆ
Kubernetes ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆã‚’ä½œæˆã—ã€FastAPI ã‚¢ãƒ—ãƒªã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã¾ã™ã€‚
Kubernetes Deployment, Kubernetes Service, Kubernetes Ingress ã‚’ä½œæˆã—ã‚¢ã‚¯ã‚»ã‚¹ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
```bash
kubectl apply -f api/fastapi-deploy.yaml
kubectl apply -f api/fastapi-svc.yaml
kubectl apply -f api/fastapi-ingress.yaml
```

### host ã® /etc/hosts ã«`api.local`ã‚’è¿½åŠ 
```bash
sudo sh -c 'echo "127.0.0.1 api.local" >> /etc/hosts'
```

### Step 4ï¼škind ãƒãƒ¼ãƒ‰ã«ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ­ãƒ¼ãƒ‰
```bash
# ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå‚ç…§ã—ã¦ã„ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸åã‚’ç¢ºèªã™ã‚‹
kind load docker-image localhost:5001/fastapi-iris:latest --name agritech-mlops
docker exec -it agritech-mlops-control-plane ctr -n k8s.io images ls | grep fastapi-iris || true
# Deployment ã‚’å†èµ·å‹•ã™ã‚‹
kubectl -n mlflow rollout restart deployment/fastapi
kubectl -n mlflow rollout status deployment/fastapi
```





## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
### FastAPI ã‚¢ãƒ—ãƒªã«ã‚¢ã‚¯ã‚»ã‚¹ã§ããªã„
- kubectl -n mlflow rollout status deployment/fastapi => replicas are pending termination... ã®ã¾ã¾å›ºã¾ã£ã¦ã—ã¾ã†
[åŸå› ] å¤ã„ ReplicaSet ãŒæ®‹ã£ã¦ã„ã¦ã€æ–°ã—ã„ Pod ãŒã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã•ã‚Œãªã„ã€‚
[åŸå› ã®åŸå› ] ImagePullBackOff ãŒç™ºç”Ÿã—ã¦ã„ã‚‹ã€‚
[å¯¾ç­–] imagePullPolicy ã‚’ IfNotPresent ã«è¨­å®šã—ã€å¤ã„ ReplicaSet ã‚’å‰Šé™¤å¾Œã€kind ãƒãƒ¼ãƒ‰ã«ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ­ãƒ¼ãƒ‰ã—ç›´ã—ã¦ã‹ã‚‰ Deployment ã‚’å†èµ·å‹•ã™ã‚‹ã€‚
```bash
kubectl -n mlflow get deployment fastapi -o wide; echo '---'; kubectl -n mlflow describe deployment fastapi; echo '---'; kubectl -n mlflow get rs -o wide --sort-by=.metadata.creationTimestamp; echo '---'; kubectl -n mlflow get pods -o wide; echo '---'; kubectl -n mlflow get events --sort-by='.lastTimestamp' | tail -n 40

kubectl -n mlflow get deployment fastapi -o wide; echo '---'; kubectl -n mlflow describe deployment fastapi | sed -n '1,240p'; echo '---'; kubectl -n mlflow get pods -o wide --show-labels; echo '---'; kubectl -n mlflow get pods -o jsonpath='{range .items[*]}{.metadata.name}{"\t"}{.metadata.ownerReferences[0].name}{"\n"}{end}'


# fastapi ãƒ‡ãƒ—ãƒ­ã‚¤ã®ã€ŒNewReplicaSetã€ã¯ fastapi-b6d6d5574ã€‚ãŸã ã—å¤ã„ RS fastapi-5cb87cffb8 ã«ã‚‚ãƒãƒƒãƒ‰ãŒã‚ã‚Šã€ä¸¡æ–¹ã®ãƒãƒƒãƒ‰ã¯ ImagePullBackOff ã§ Ready ã«ãªã£ã¦ã„ãªã„ã€‚
# DESIRED/CURRENT/READY ãŒ 0 ã® RS ã¯å‰Šé™¤ã—ã¦ã‚ˆã„ã€‚-> ãƒ‡ãƒ—ãƒ­ã‚¤ã‚’æ­£å¸¸åŒ–ã—ã¦ã‹ã‚‰å‰Šé™¤ã€‚ç›´æ¥å‰Šã‚‹ã¨ç¨¼åƒä¸­ã® Pod ã‚’æ¶ˆã—ã¦ã—ã¾ã†å¯èƒ½æ€§ãŒã‚ã‚Š

# å®Œå…¨ã«ä¸è¦ãª ReplicaSet ã‚’å‰Šé™¤
kubectl -n mlflow get rs -o jsonpath='{range .items[?(@.status.replicas==0)]}{.metadata.name}{"\n"}{end}'
kubectl -n mlflow delete rs <rs-name1> <rs-name2> ...

# Deployment ã®å±¥æ­´ã‚’ 2 ã«åˆ¶é™ã—ã¦å¤ã„ RS ã‚’è‡ªå‹•å‰Šé™¤ã™ã‚‹è¨­å®š
kubectl -n mlflow patch deployment fastapi -p '{"spec":{"revisionHistoryLimit":2}}'

# kind ãƒãƒ¼ãƒ‰ã«ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ­ãƒ¼ãƒ‰ã—ç›´ã™
kind load docker-image localhost:5001/fastapi-iris:latest --name agritech-mlops
kubectl -n mlflow rollout restart deployment/fastapi; kubectl -n mlflow rollout status deployment/fastapi --timeout=90s
# => timeout...

# api/fastapi-deploy.yaml ã« imagePullPolicy: IfNotPresent è¿½åŠ ã—ã¦å†ãƒ‡ãƒ—ãƒ­ã‚¤
# kubectl apply -f api/fastapi-deploy.yaml
# ã¾ãŸã¯ä¸‹è¨˜ã‚³ãƒãƒ³ãƒ‰ã§ãƒ‘ãƒƒãƒé©ç”¨
kubectl -n mlflow patch deployment fastapi -p '{"spec":{"template":{"spec":{"containers":[{"name":"fastapi","imagePullPolicy":"IfNotPresent"}]}}}}'

# Deployment å†èµ·å‹•
kubectl -n mlflow rollout restart deployment/fastapi; kubectl -n mlflow rollout status deployment/fastapi --timeout=90s
# => OK
```



## ä½¿ã†ãƒ¢ãƒ‡ãƒ« models:/argo-dag-demo/1 ã‚’ MLflow ã«ç™»éŒ²
```bash
# æ‰‹å‹•ã§ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰èµ·å‹•ï¼ˆãƒ­ã‚°ã‚’ /tmp/mlflow-pf.log ã«ä¿å­˜ï¼‰
nohup kubectl -n mlflow port-forward svc/mlflow-svc 5005:5000 --address 127.0.0.1 > /tmp/mlflow-pf.log 2>&1 & echo $!

# models:/argo-dag-demo/1 ã‚’ç™»éŒ²ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
python - <<'PY'
import os
import mlflow
from mlflow.tracking import MlflowClient
import tempfile
import shutil

mlflow.set_tracking_uri('http://127.0.0.1:5005')
client = MlflowClient()
exp = mlflow.get_experiment_by_name('argo-dag-demo')
exp_id = exp.experiment_id if exp else client.create_experiment('argo-dag-demo')
runs = client.search_runs([exp_id], order_by=["attributes.start_time DESC"], max_results=50)

for r in runs:
    run_id = r.info.run_id
    print('Inspecting run', run_id)
    arts = client.list_artifacts(run_id, path='model')
    if not arts:
        print(' no model artifact in run')
        continue
    for a in arts:
        if a.path.endswith('model.pkl') or a.path == 'model.pkl':
            print(' found model file at', a.path)
            tmpdir = tempfile.mkdtemp(prefix='mlflow_register_')
            new_run_id = None
            try:
                dl = client.download_artifacts(run_id, a.path, dst_path=tmpdir)
                print(' downloaded to', dl)
                save_dir = os.path.join(tmpdir, 'pyfunc_model')
                os.makedirs(save_dir, exist_ok=True)
                from mlflow.pyfunc import PythonModel
                import joblib

                class WrapperModel(PythonModel):
                    def load_context(self, context):
                        import joblib
                        self.model = joblib.load(context.artifacts['model'])
                    def predict(self, context, model_input):
                        return self.model.predict(model_input)

                artifact_path = os.path.join(tmpdir, os.path.basename(dl))
                mlflow.pyfunc.save_model(path=save_dir, python_model=WrapperModel(), artifacts={'model': artifact_path})
                print('Saved pyfunc model to', save_dir)
                # create temp run to upload artifact
                new_run = client.create_run(exp_id)
                new_run_id = new_run.info.run_id
                print('Created temp run', new_run_id)
                client.log_artifacts(new_run_id, save_dir, artifact_path='model')
                print('Logged artifacts to run')
                model_uri = f'runs:/{new_run_id}/model'
                print('Registering model from', model_uri)
                mv = mlflow.register_model(model_uri, 'argo-dag-demo')
                print('Registered model version', mv.version)
                client.transition_model_version_stage('argo-dag-demo', mv.version, stage='None')
            finally:
                # å¿…ãšãƒ©ãƒ³ã‚’çµ‚äº†ã•ã›ã‚‹ï¼ˆä¾‹å¤–ãŒèµ·ãã¦ã‚‚æ®‹ã•ãªã„ï¼‰
                if new_run_id:
                    try:
                        client.set_terminated(new_run_id, status='FINISHED')
                        print('Terminated temp run', new_run_id)
                    except Exception as e:
                        print('Failed to terminate temp run', new_run_id, e)
                shutil.rmtree(tmpdir)
                # çµ‚äº†å¾Œã¯æ¬¡ã®å€™è£œã‚’æ¢ã—ãŸã‘ã‚Œã° continue ã™ã‚‹ï¼ˆå…ƒã‚³ãƒ¼ãƒ‰ã¯æ—©æœŸçµ‚äº†ã—ã¦ã„ãŸï¼‰
print('Done')
PY


# ãƒ­ã‚°ç¢ºèª
tail -f /tmp/mlflow-pf.log

# ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢ï¼ˆPIDãŒã‚ã‹ã‚Œã° kill <PID>ã€ç°¡æ˜“ã«ï¼‰
pkill -f "kubectl -n mlflow port-forward .*5005:5000"

# ãƒãƒ¼ãƒˆç¢ºèª
ss -ltnp | grep 5005


# ğŸ‘†ã§ç™»éŒ²ã—ãŸmodelã®RunsãŒrunningã®ã¾ã¾ã¾ã®å ´åˆã€ä¸‹è¨˜ã§å¼·åˆ¶çµ‚äº†ã•ã›ã‚‹
python - <<'PY'
from mlflow.tracking import MlflowClient
import mlflow
mlflow.set_tracking_uri('http://127.0.0.1:5005')
client = MlflowClient()
exp = client.get_experiment_by_name('argo-dag-demo')
if not exp:
    print('Experiment argo-dag-demo not found')
    raise SystemExit(1)
exp_id = exp.experiment_id
runs = client.search_runs([exp_id], filter_string="attributes.status='RUNNING'", max_results=500)
if not runs:
    print('No RUNNING runs found')
else:
    print('Found', len(runs), 'RUNNING runs:')
    for r in runs:
        rid = r.info.run_id
        print('-', rid)
    for r in runs:
        rid = r.info.run_id
        try:
            client.set_terminated(rid, status='FINISHED')
            print('Terminated', rid)
        except Exception as e:
            print('Failed to terminate', rid, e)
# show summary
runs2 = client.search_runs([exp_id], order_by=["attributes.start_time DESC"], max_results=200)
print('--- runs after update ---')
for r in runs2[:20]:
    print(r.info.run_id, r.info.status)
PY

```
